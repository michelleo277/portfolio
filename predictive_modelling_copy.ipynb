{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c68e55-639e-435c-b635-4cf3d3ee7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, mean_squared_error, mean_absolute_error, \n",
    "                             r2_score, classification_report, confusion_matrix, \n",
    "                             precision_recall_curve)\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import (RandomForestClassifier, RandomForestRegressor, \n",
    "                              GradientBoostingClassifier, GradientBoostingRegressor)\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# Other utilities\n",
    "import joblib\n",
    "import pickle\n",
    "from scipy.stats import boxcox\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "df_transformed = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:\n",
    "\n",
    "Since the data was collected in-house through a multiple-choice survey without open-ended questions, the cleaning process is relatively straightforward. However, there are still a few aspects to check:\n",
    "\n",
    "- **Data types:** Ensure correct classification, primarily int64 and object.\n",
    "- **Duplicates and missing values:** Identify and handle any null or duplicate entries.\n",
    "- **Whitespace:** Extra spaces have been removed for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Outliers  \n",
    "\n",
    "While some machine learning models are robust to outliers, understanding their presence is crucial, as many statistical techniques assume normally distributed errors. Skewed data can impact model performance, especially for algorithms sensitive to variance, such as linear regression and SVMs.  \n",
    "\n",
    "Common methods for detecting outliers include:  \n",
    "- **Z-score**: Identifies data points that deviate significantly from the mean.  \n",
    "- **Interquartile Range (IQR) Method**: Flags values that fall beyond 1.5 times the IQR.  \n",
    "- **Visualization Techniques**: Box plots, histograms, and density plots provide intuitive insights into data distribution.  \n",
    "\n",
    "For this analysis, I used **box plots** to visualize the spread and detect potential outliers effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a boxplot for all numerical columns\n",
    "sns.boxplot(data=df, orient=\"h\")\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Outlier Detection using Boxplots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results are difficult to interpret due to scaling in the graph above. To improve clarity, I created a focused visualization of selected columns below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['NumCompaniesWorked', 'PerformanceRating', 'StockOptionLevel','TotalWorkingYears','TrainingTimesLastYear','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']  # Replace with actual column names\n",
    "\n",
    "# Plot only selected columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[columns_to_check], orient=\"h\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the box plots for each feature by Attrition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to compare with Attrition\n",
    "columns_to_check = ['NumCompaniesWorked','StockOptionLevel','MonthlyIncome','MonthlyRate','DailyRate',\n",
    "                    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',\n",
    "                    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "# Loop through each column and create a boxplot\n",
    "for col in columns_to_check:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=df['Attrition'], y=df[col], data=df)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"Distribution of {col} Across Attrition\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently it appears that people who leave will do so around the 2.5 year mark and are earlier on in their careers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing categorical features against Attrition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(8, 5))  # New figure for each plot\n",
    "\n",
    "    # Group and count occurrences\n",
    "    category_counts = df.groupby(['Attrition', col]).size().unstack()\n",
    "\n",
    "    # **Sort columns by total count (sum over rows) in ascending order**\n",
    "    category_counts = category_counts[category_counts.sum(axis=0).sort_values(ascending=False).index]\n",
    "\n",
    "    # Plot stacked bar chart\n",
    "    category_counts.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "\n",
    "    # Labels & Title\n",
    "    plt.xlabel('Attrition')\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Stacked Bar Chart: {col} vs {'Attrition'}\")\n",
    "    plt.legend(title=col)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','OverTime']\n",
    "\n",
    "summary_tables = {}\n",
    "\n",
    "# Loop through each categorical column\n",
    "for cat_col in categorical_columns:\n",
    "    # Cross-tabulation of Attrition and categorical variable\n",
    "    crosstab = pd.crosstab(df[cat_col], df['Attrition'], margins=True)\n",
    "\n",
    "    # Convert counts to percentages\n",
    "    crosstab_percentage = crosstab.div(crosstab[\"All\"], axis=0) * 100\n",
    "\n",
    "    # Combine both count & percentage into a single DataFrame\n",
    "    summary_table = crosstab.copy()\n",
    "    for col in crosstab.columns[:-1]:  # Exclude the \"All\" column\n",
    "        summary_table[col] = summary_table[col].astype(str) + \" (\" + crosstab_percentage[col].round(2).astype(str) + \"%)\"\n",
    "\n",
    "    # Store the formatted summary table\n",
    "    summary_tables[cat_col] = summary_table.drop(columns=[\"All\"])  # Remove the total count column\n",
    "\n",
    "    # Print the table\n",
    "    print(f\"\\nðŸ“Š Summary Table for {cat_col} vs Attrition:\\n\")\n",
    "    print(summary_tables[cat_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze categorical columns by grouping them by the **Attrition** column using bar charts and percentage tables. Given the presence of outliers and the imbalance in some categories, key observations include:  \n",
    "\n",
    "1. **25%** of employees who left the company were frequent travelers.  \n",
    "2. **20%** of employees in the **Sales** department left.  \n",
    "3. **Technical** and **Marketing** employees had some of the highest attrition rates at **22-24%**.  \n",
    "4. While **26%** of HR employees left, this group had a small sample size (only **27 employees** in the study)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data contains outliers, we will address them before analyzing correlations and other patterns. Instead of removing data, we will apply the Box-Cox transformation, as the context of these outliers is unknown.\n",
    "\n",
    "The Box-Cox transformation is a powerful technique for handling outliers and improving normality, making the data more suitable for predictive modeling. It is particularly useful because it adapts to different distributions, ensuring a more stable and well-behaved dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Function to apply Box-Cox transformation\n",
    "def apply_boxcoxs(series):\n",
    "    if (series <= 0).any():  # Shift data if necessary\n",
    "        series += abs(series.min()) + 1  # Shift to positive\n",
    "    return boxcox(series)[0]  # Apply transformation\n",
    "\n",
    "# Apply Box-Cox to numerical columns, skipping constant columns\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        df_transformed[col] = apply_boxcoxs(df[col])\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping {col}: {e}\")\n",
    "\n",
    "# Keep categorical columns unchanged\n",
    "df_transformed[cat_cols] = df[cat_cols]\n",
    "df_transformed['Attrition'] = df_transformed['Attrition'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of Unskewed Data\n",
    "Below are the top 20 features most correlated with Attrition. Key insights include:\n",
    "\n",
    "- Employees who work overtime are more likely to leave.\n",
    "\n",
    "- Individuals who have never been married show higher attrition rates.\n",
    "\n",
    "- Sales Representatives are among the most likely to leave.\n",
    "\n",
    "These correlations provide a glance into employee retention patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_transformed, drop_first=True)  # Creates numeric columns for categories\n",
    "\n",
    "# Compute correlation with Attrition\n",
    "corr_matrix = df_encoded.corr()\n",
    "\n",
    "# Select top 20 features most correlated with Attrition\n",
    "top_corr_features = corr_matrix.nlargest(20, \"Attrition\")[\"Attrition\"].index\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df_encoded[top_corr_features].corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\": 10})\n",
    "\n",
    "plt.title(\"Top 20 Correlated Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numeric using one-hot encoding\n",
    "data_encoded = pd.get_dummies(df_transformed, drop_first=True)  # Avoid dummy variable trap\n",
    "\n",
    "# Compute correlation with Attrition\n",
    "corr_values = data_encoded.drop(columns=['Attrition','StandardHours','EmployeeCount'], errors='ignore').corrwith(data_encoded['Attrition']).sort_values()\n",
    "\n",
    "# Plot correlation values\n",
    "plt.figure(figsize=(10, 15))\n",
    "corr_values.plot(kind='barh')\n",
    "plt.title(\"Correlation of All Features with Attrition\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance  \n",
    "\n",
    "Since employee attrition is typically lower than retention, class imbalance can impact model performance. To address this:  \n",
    "\n",
    "1. **Detect and quantify class imbalance** by calculating the distribution of attrition classes.  \n",
    "2. **Implement class weighting** in models that support it to ensure balanced learning.  \n",
    "\n",
    "This approach helps improve model accuracy, particularly for predicting the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attrition Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Attrition'\n",
    "\n",
    "# Check attrition distribution (already binary 0=stayed, 1=left)\n",
    "attrition_counts = df[target_col].value_counts()\n",
    "print(\"Attrition distribution:\")\n",
    "print(attrition_counts)\n",
    "\n",
    "# Calculate attrition rate\n",
    "left_count = attrition_counts.get(1, 0)\n",
    "total_count = len(df)\n",
    "attrition_rate = left_count / total_count\n",
    "print(f\"Attrition rate: {attrition_rate:.2%}\")\n",
    "\n",
    "# Check for class imbalance\n",
    "stayed_count = attrition_counts.get(0, 0)\n",
    "if left_count > 0:\n",
    "    imbalance_ratio = stayed_count / left_count\n",
    "    print(f\"Class imbalance ratio (stayed:left): {imbalance_ratio:.2f}:1\")\n",
    "    if imbalance_ratio > 3:\n",
    "        print(\"Note: Dataset has significant class imbalance.\")\n",
    "else:\n",
    "    print(\"Warning: No attrition cases found in the dataset.\")\n",
    "    imbalance_ratio = 999  # Set a high value to trigger class weight adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Attrition'\n",
    "# Split Data\n",
    "X = df_transformed.drop(target_col, axis=1)\n",
    "y = df_transformed[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print Dataset Summary\n",
    "print(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "print(f\"Training attrition rate: {np.mean(y_train):.2%}, Test attrition rate: {np.mean(y_test):.2%}\")\n",
    "\n",
    "# Preprocessing Pipeline (No Imputation Since No Nulls)\n",
    "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col != target_col]\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "preprocessor = ColumnTransformer([\n",
    "    \n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Handle Class Imbalance\n",
    "class_weight = {0: 1, 1: imbalance_ratio} if imbalance_ratio > 3 else None\n",
    "\n",
    "# Define Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight=class_weight),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight=class_weight),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, scale_pos_weight=imbalance_ratio if imbalance_ratio > 3 else 1),\n",
    "    'SVC': SVC(probability=True, random_state=42, class_weight=class_weight),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight=class_weight)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the attrition rates are very similar between training and test sets, it confirms that the split was done properly (stratified sampling). This prevents bias in the model.\n",
    "\n",
    "**Class Imbalance:** Only about 16% of employees leave, so naturally the dataset is imbalanced. Models must handle this imbalance to avoid favoring the majority class (employees who stay).\n",
    "\n",
    "**Real-World Representation:** If the training and test data had very different attrition rates, the model might struggle to generalize. But here, the similarity means the model is trained on a representative sample of the real workforce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Compute Metrics\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None,\n",
    "        'Attrition Precision': precision_score(y_test, y_pred, pos_label=1),\n",
    "        'Attrition Recall': recall_score(y_test, y_pred, pos_label=1),\n",
    "        'Attrition F1': f1_score(y_test, y_pred, pos_label=1),\n",
    "        'Model': pipeline\n",
    "    }\n",
    "    \n",
    "    results[name] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Model Comparison\n",
    "metrics_df = pd.DataFrame({k: {m: v[m] for m in v if m != \"Model\"} for k, v in results.items()}).T\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Identify Best Models\n",
    "best_metric = 'Attrition Recall'\n",
    "best_model_name = max(results, key=lambda k: results[k][best_metric] or 0)\n",
    "best_model = results[best_model_name]['Model']\n",
    "print(f\"\\nBest model based on {best_metric}: {best_model_name}\")\n",
    "\n",
    "# Feature Importance for Tree-Based Models\n",
    "if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "    cat_features = preprocessor.transformers_[1][2]\n",
    "    cat_feature_names = preprocessor.transformers_[1][1].steps[0][1].get_feature_names_out(cat_features)\n",
    "    feature_names = np.concatenate([numeric_cols, cat_feature_names])\n",
    "    \n",
    "    importances = best_model.named_steps['model'].feature_importances_\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# Precision-Recall Curve and Optimal Threshold\n",
    "if hasattr(best_model.named_steps['model'], 'predict_proba'):\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)] if len(thresholds) > 0 else 0.5\n",
    "\n",
    "    print(f\"\\nOptimal probability threshold for attrition: {optimal_threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The model that best identifies employees likely to leave (highest Attrition Recall) is Logistic Regression because it correctly flags the most potential leavers, making it the best choice if catching as many at-risk employees as possible is the goal.\n",
    "\n",
    "If we look at overall performance (Accuracy, Precision, Recall, F1 Score, and ROC-AUC), XGBoost and Gradient Boosting perform best.\n",
    "\n",
    "XGBoost has the highest F1 Score (0.841) and Accuracy (86.39%), meaning it's a strong all-around model.\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "- Logistic Regression is best at finding leavers (high recall: 61.7%) but not as precise (some false positives).\n",
    "\n",
    "- Random Forest & KNN have poor recall, meaning they miss a lot of people who actually leave.\n",
    "\n",
    "- XGBoost & Gradient Boosting offer a balance, but they still miss many at-risk employees.\n",
    "\n",
    "\n",
    "**Optimal Probability Threshold (0.6073):**\n",
    "\n",
    "Instead of using the default 50% probability threshold, setting it to 0.6073 improves the modelâ€™s ability to detect leavers without too many false alarms.\n",
    "\n",
    "### Business Takeaway\n",
    "If identifying at-risk employees is the priority (minimizing missed leavers), go with Logistic Regression.\n",
    "\n",
    "If a balance between predicting leavers and overall accuracy is needed, XGBoost or Gradient Boosting is better.\n",
    "\n",
    "Adjusting the probability threshold to 0.6073 makes the model more effective at detecting employees likely to leave."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
